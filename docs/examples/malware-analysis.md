---
title: Malware Analysis Analyzer
---

# Malware Analysis Analyzer

This example demonstrates how to build a comprehensive malware analysis analyzer that performs static and dynamic analysis of suspicious files.

## Overview

The Malware Analysis Analyzer combines multiple analysis techniques to provide detailed malware detection and classification. It demonstrates:

- Static analysis using YARA rules
- PE file analysis
- Behavioral analysis
- Sandbox integration
- Machine learning classification
- Comprehensive reporting

## Implementation

```python
# malware_analysis_analyzer.py
from __future__ import annotations

import hashlib
import json
import os
import subprocess
import tempfile
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

import yara
import pefile
from sentineliqsdk import Analyzer, runner


@dataclass
class YARARule:
    """YARA rule configuration."""
    name: str
    path: str
    weight: float = 1.0


@dataclass
class SandboxConfig:
    """Sandbox configuration."""
    name: str
    api_url: str
    api_key: str
    timeout: int = 300
    enabled: bool = True


class MalwareAnalysisAnalyzer(Analyzer):
    """Comprehensive malware analysis analyzer."""
    
    def __init__(self, input_data):
        super().__init__(input_data)
        self.yara_rules = self._load_yara_rules()
        self.sandbox_configs = self._load_sandbox_configs()
        self.ml_model = self._load_ml_model()
        self.temp_dir = tempfile.mkdtemp()
    
    def _load_yara_rules(self) -> List[YARARule]:
        """Load YARA rules for malware detection."""
        rules = []
        
        # Load built-in rules
        builtin_rules = [
            ("Malware_Generic", "rules/malware_generic.yar", 1.0),
            ("Ransomware", "rules/ransomware.yar", 1.5),
            ("Trojan", "rules/trojan.yar", 1.2),
            ("Backdoor", "rules/backdoor.yar", 1.3),
            ("Downloader", "rules/downloader.yar", 1.1)
        ]
        
        for name, path, weight in builtin_rules:
            if os.path.exists(path):
                rules.append(YARARule(name=name, path=path, weight=weight))
        
        # Load custom rules from configuration
        custom_rules = self.get_param("config.custom_yara_rules", default=[])
        for rule_config in custom_rules:
            rules.append(YARARule(
                name=rule_config["name"],
                path=rule_config["path"],
                weight=rule_config.get("weight", 1.0)
            ))
        
        return rules
    
    def _load_sandbox_configs(self) -> List[SandboxConfig]:
        """Load sandbox configurations."""
        configs = []
        
        # Cuckoo Sandbox
        cuckoo_api_key = self.get_param("config.cuckoo_api_key")
        if cuckoo_api_key:
            configs.append(SandboxConfig(
                name="cuckoo",
                api_url=self.get_param("config.cuckoo_api_url", "http://localhost:8090"),
                api_key=cuckoo_api_key,
                timeout=300
            ))
        
        # Hybrid Analysis
        ha_api_key = self.get_param("config.hybrid_analysis_api_key")
        if ha_api_key:
            configs.append(SandboxConfig(
                name="hybrid_analysis",
                api_url="https://www.hybrid-analysis.com/api/v2",
                api_key=ha_api_key,
                timeout=600
            ))
        
        # Any.run
        anyrun_api_key = self.get_param("config.anyrun_api_key")
        if anyrun_api_key:
            configs.append(SandboxConfig(
                name="anyrun",
                api_url="https://api.any.run/v1",
                api_key=anyrun_api_key,
                timeout=300
            ))
        
        return configs
    
    def _load_ml_model(self) -> Optional[Any]:
        """Load machine learning model for malware classification."""
        model_path = self.get_param("config.ml_model_path")
        if model_path and os.path.exists(model_path):
            try:
                import joblib
                return joblib.load(model_path)
            except ImportError:
                print("Warning: joblib not available, ML model disabled")
            except Exception as e:
                print(f"Warning: Failed to load ML model: {e}")
        return None
    
    def run(self) -> None:
        """Main analysis logic."""
        if self.data_type != "file":
            self.error(f"Malware analysis only supports files, got: {self.data_type}")
        
        file_path = self.get_param("file")
        if not os.path.exists(file_path):
            self.error(f"File not found: {file_path}")
        
        # Perform comprehensive malware analysis
        try:
            analysis_result = self._analyze_malware(file_path)
            self.report(analysis_result)
        except Exception as e:
            self.error(f"Malware analysis failed: {str(e)}")
        finally:
            # Clean up temporary files
            self._cleanup_temp_files()
    
    def _analyze_malware(self, file_path: str) -> Dict[str, Any]:
        """Perform comprehensive malware analysis."""
        file_info = self._get_file_info(file_path)
        
        # Static analysis
        static_analysis = self._perform_static_analysis(file_path, file_info)
        
        # Dynamic analysis (sandbox)
        dynamic_analysis = self._perform_dynamic_analysis(file_path)
        
        # Machine learning analysis
        ml_analysis = self._perform_ml_analysis(file_path, file_info)
        
        # Combine all analysis results
        combined_analysis = self._combine_analysis_results(
            file_path, file_info, static_analysis, dynamic_analysis, ml_analysis
        )
        
        return combined_analysis
    
    def _get_file_info(self, file_path: str) -> Dict[str, Any]:
        """Get comprehensive file information."""
        path = Path(file_path)
        stat = path.stat()
        
        # Calculate file hashes
        hashes = self._calculate_hashes(file_path)
        
        # Detect file type
        file_type = self._detect_file_type(file_path)
        
        return {
            "filename": path.name,
            "size": stat.st_size,
            "created": stat.st_ctime,
            "modified": stat.st_mtime,
            "extension": path.suffix.lower(),
            "hashes": hashes,
            "file_type": file_type,
            "mime_type": self._detect_mime_type(file_path)
        }
    
    def _calculate_hashes(self, file_path: str) -> Dict[str, str]:
        """Calculate multiple hash types for the file."""
        hashes = {}
        
        md5_hash = hashlib.md5()
        sha1_hash = hashlib.sha1()
        sha256_hash = hashlib.sha256()
        
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b""):
                md5_hash.update(chunk)
                sha1_hash.update(chunk)
                sha256_hash.update(chunk)
        
        return {
            "md5": md5_hash.hexdigest(),
            "sha1": sha1_hash.hexdigest(),
            "sha256": sha256_hash.hexdigest()
        }
    
    def _detect_file_type(self, file_path: str) -> str:
        """Detect file type using file command."""
        try:
            result = subprocess.run(['file', file_path], capture_output=True, text=True)
            return result.stdout.strip()
        except Exception:
            return "Unknown"
    
    def _detect_mime_type(self, file_path: str) -> str:
        """Detect MIME type."""
        import mimetypes
        mime_type, _ = mimetypes.guess_type(file_path)
        return mime_type or "application/octet-stream"
    
    def _perform_static_analysis(self, file_path: str, file_info: Dict[str, Any]) -> Dict[str, Any]:
        """Perform static analysis of the file."""
        analysis = {
            "yara_matches": [],
            "pe_analysis": {},
            "entropy_analysis": {},
            "string_analysis": {},
            "verdict": "safe",
            "confidence": "low"
        }
        
        # YARA rule matching
        yara_matches = self._run_yara_rules(file_path)
        analysis["yara_matches"] = yara_matches
        
        # PE file analysis (if applicable)
        if file_info["extension"] in [".exe", ".dll", ".sys"]:
            pe_analysis = self._analyze_pe_file(file_path)
            analysis["pe_analysis"] = pe_analysis
        
        # Entropy analysis
        entropy_analysis = self._analyze_entropy(file_path)
        analysis["entropy_analysis"] = entropy_analysis
        
        # String analysis
        string_analysis = self._analyze_strings(file_path)
        analysis["string_analysis"] = string_analysis
        
        # Determine static analysis verdict
        analysis["verdict"], analysis["confidence"] = self._determine_static_verdict(analysis)
        
        return analysis
    
    def _run_yara_rules(self, file_path: str) -> List[Dict[str, Any]]:
        """Run YARA rules against the file."""
        matches = []
        
        for rule in self.yara_rules:
            try:
                rules = yara.compile(rule.path)
                yara_matches = rules.match(file_path)
                
                for match in yara_matches:
                    matches.append({
                        "rule_name": match.rule,
                        "rule_file": rule.name,
                        "weight": rule.weight,
                        "tags": match.tags,
                        "meta": match.meta,
                        "strings": [str(s) for s in match.strings],
                        "namespace": match.namespace
                    })
            except Exception as e:
                matches.append({
                    "rule_name": rule.name,
                    "error": str(e),
                    "weight": rule.weight
                })
        
        return matches
    
    def _analyze_pe_file(self, file_path: str) -> Dict[str, Any]:
        """Analyze PE file for malware characteristics."""
        try:
            pe = pefile.PE(file_path)
            
            analysis = {
                "sections": [],
                "imports": [],
                "exports": [],
                "suspicious_characteristics": [],
                "entropy": {},
                "verdict": "safe"
            }
            
            # Analyze sections
            for section in pe.sections:
                section_data = section.get_data()
                section_info = {
                    "name": section.Name.decode('ascii', errors='ignore').rstrip('\x00'),
                    "virtual_address": section.VirtualAddress,
                    "virtual_size": section.Misc_VirtualSize,
                    "raw_size": section.SizeOfRawData,
                    "characteristics": section.Characteristics,
                    "entropy": self._calculate_entropy(section_data),
                    "suspicious": False
                }
                
                # Check for suspicious section characteristics
                if section.Characteristics & 0x20000000:  # IMAGE_SCN_MEM_EXECUTE
                    section_info["suspicious"] = True
                    analysis["suspicious_characteristics"].append("Executable section")
                
                if section_info["entropy"] > 7.0:  # High entropy
                    section_info["suspicious"] = True
                    analysis["suspicious_characteristics"].append("High entropy section")
                
                analysis["sections"].append(section_info)
            
            # Analyze imports
            if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                for entry in pe.DIRECTORY_ENTRY_IMPORT:
                    dll_name = entry.dll.decode('ascii', errors='ignore')
                    imports = [imp.name.decode('ascii', errors='ignore') for imp in entry.imports if imp.name]
                    
                    import_info = {
                        "dll": dll_name,
                        "functions": imports,
                        "suspicious": False
                    }
                    
                    # Check for suspicious imports
                    suspicious_apis = {
                        'CreateProcess', 'WriteProcessMemory', 'VirtualAlloc',
                        'LoadLibrary', 'GetProcAddress', 'RegOpenKey',
                        'RegSetValue', 'DeleteFile', 'MoveFile', 'CopyFile'
                    }
                    
                    if any(api in suspicious_apis for api in imports):
                        import_info["suspicious"] = True
                        analysis["suspicious_characteristics"].append("Suspicious imports")
                    
                    analysis["imports"].append(import_info)
            
            # Calculate overall PE entropy
            analysis["entropy"] = {
                "overall": self._calculate_entropy(pe.__data__),
                "sections": [s["entropy"] for s in analysis["sections"]]
            }
            
            # Determine PE verdict
            if analysis["suspicious_characteristics"]:
                analysis["verdict"] = "suspicious"
            else:
                analysis["verdict"] = "safe"
            
            pe.close()
            return analysis
            
        except Exception as e:
            return {"error": str(e), "verdict": "unknown"}
    
    def _calculate_entropy(self, data: bytes) -> float:
        """Calculate Shannon entropy of data."""
        if not data:
            return 0.0
        
        # Count byte frequencies
        byte_counts = [0] * 256
        for byte in data:
            byte_counts[byte] += 1
        
        # Calculate entropy
        entropy = 0.0
        data_len = len(data)
        for count in byte_counts:
            if count > 0:
                probability = count / data_len
                entropy -= probability * (probability.bit_length() - 1)
        
        return entropy
    
    def _analyze_entropy(self, file_path: str) -> Dict[str, Any]:
        """Analyze file entropy for packed/encrypted content."""
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
            
            # Calculate overall entropy
            overall_entropy = self._calculate_entropy(data)
            
            # Calculate entropy in chunks
            chunk_size = 1024
            chunk_entropies = []
            
            for i in range(0, len(data), chunk_size):
                chunk = data[i:i + chunk_size]
                chunk_entropy = self._calculate_entropy(chunk)
                chunk_entropies.append(chunk_entropy)
            
            # Analyze entropy distribution
            high_entropy_chunks = sum(1 for e in chunk_entropies if e > 7.0)
            entropy_ratio = high_entropy_chunks / len(chunk_entropies) if chunk_entropies else 0
            
            return {
                "overall_entropy": overall_entropy,
                "chunk_entropies": chunk_entropies,
                "high_entropy_chunks": high_entropy_chunks,
                "entropy_ratio": entropy_ratio,
                "is_packed": overall_entropy > 7.5 or entropy_ratio > 0.8,
                "is_encrypted": overall_entropy > 7.8
            }
            
        except Exception as e:
            return {"error": str(e)}
    
    def _analyze_strings(self, file_path: str) -> Dict[str, Any]:
        """Analyze strings in the file for suspicious patterns."""
        try:
            # Extract strings using strings command
            result = subprocess.run(['strings', file_path], capture_output=True, text=True)
            strings = result.stdout.split('\n')
            
            # Analyze strings for suspicious patterns
            suspicious_patterns = {
                "network_indicators": [],
                "file_operations": [],
                "registry_operations": [],
                "process_operations": [],
                "suspicious_strings": []
            }
            
            for string in strings:
                string_lower = string.lower()
                
                # Network indicators
                if any(pattern in string_lower for pattern in ['http://', 'https://', 'ftp://', 'tcp://']):
                    suspicious_patterns["network_indicators"].append(string)
                
                # File operations
                if any(pattern in string_lower for pattern in ['createfile', 'deletefile', 'movefile', 'copyfile']):
                    suspicious_patterns["file_operations"].append(string)
                
                # Registry operations
                if any(pattern in string_lower for pattern in ['regopenkey', 'regsetvalue', 'regdeletevalue']):
                    suspicious_patterns["registry_operations"].append(string)
                
                # Process operations
                if any(pattern in string_lower for pattern in ['createprocess', 'terminateprocess', 'openprocess']):
                    suspicious_patterns["process_operations"].append(string)
                
                # Suspicious strings
                if any(pattern in string_lower for pattern in ['malware', 'virus', 'trojan', 'backdoor', 'keylogger']):
                    suspicious_patterns["suspicious_strings"].append(string)
            
            return {
                "total_strings": len(strings),
                "suspicious_patterns": suspicious_patterns,
                "suspicious_count": sum(len(patterns) for patterns in suspicious_patterns.values())
            }
            
        except Exception as e:
            return {"error": str(e)}
    
    def _determine_static_verdict(self, analysis: Dict[str, Any]) -> Tuple[str, str]:
        """Determine verdict based on static analysis results."""
        yara_matches = analysis.get("yara_matches", [])
        pe_analysis = analysis.get("pe_analysis", {})
        entropy_analysis = analysis.get("entropy_analysis", {})
        string_analysis = analysis.get("string_analysis", {})
        
        threat_score = 0
        
        # YARA matches
        for match in yara_matches:
            if "error" not in match:
                threat_score += match.get("weight", 1.0)
        
        # PE analysis
        if pe_analysis.get("suspicious_characteristics"):
            threat_score += len(pe_analysis["suspicious_characteristics"])
        
        # Entropy analysis
        if entropy_analysis.get("is_packed"):
            threat_score += 1
        if entropy_analysis.get("is_encrypted"):
            threat_score += 2
        
        # String analysis
        if string_analysis.get("suspicious_count", 0) > 10:
            threat_score += 1
        
        # Determine verdict
        if threat_score >= 5:
            return "malicious", "high"
        elif threat_score >= 3:
            return "suspicious", "medium"
        elif threat_score >= 1:
            return "suspicious", "low"
        else:
            return "safe", "high"
    
    def _perform_dynamic_analysis(self, file_path: str) -> Dict[str, Any]:
        """Perform dynamic analysis using sandbox."""
        if not self.sandbox_configs:
            return {"status": "disabled", "reason": "No sandbox configured"}
        
        # Use the first available sandbox
        sandbox = self.sandbox_configs[0]
        
        try:
            if sandbox.name == "cuckoo":
                return self._run_cuckoo_analysis(file_path, sandbox)
            elif sandbox.name == "hybrid_analysis":
                return self._run_hybrid_analysis(file_path, sandbox)
            elif sandbox.name == "anyrun":
                return self._run_anyrun_analysis(file_path, sandbox)
            else:
                return {"status": "error", "reason": f"Unknown sandbox: {sandbox.name}"}
        except Exception as e:
            return {"status": "error", "reason": str(e)}
    
    def _run_cuckoo_analysis(self, file_path: str, sandbox: SandboxConfig) -> Dict[str, Any]:
        """Run analysis using Cuckoo Sandbox."""
        import requests
        
        # Submit file for analysis
        with open(file_path, 'rb') as f:
            files = {'file': f}
            data = {'enforce_timeout': 1}
            headers = {'Authorization': f'Bearer {sandbox.api_key}'}
            
            response = requests.post(
                f"{sandbox.api_url}/tasks/create/file",
                files=files,
                data=data,
                headers=headers,
                timeout=30
            )
        
        if response.status_code != 200:
            return {"status": "error", "reason": f"Submission failed: {response.status_code}"}
        
        task_id = response.json()["task_id"]
        
        # Wait for analysis to complete
        start_time = time.time()
        while time.time() - start_time < sandbox.timeout:
            status_response = requests.get(
                f"{sandbox.api_url}/tasks/view/{task_id}",
                headers=headers,
                timeout=30
            )
            
            if status_response.status_code == 200:
                status_data = status_response.json()
                if status_data["task"]["status"] == "completed":
                    # Get analysis report
                    report_response = requests.get(
                        f"{sandbox.api_url}/tasks/report/{task_id}",
                        headers=headers,
                        timeout=30
                    )
                    
                    if report_response.status_code == 200:
                        return self._parse_cuckoo_report(report_response.json())
                    else:
                        return {"status": "error", "reason": "Failed to get report"}
                elif status_data["task"]["status"] == "failed":
                    return {"status": "error", "reason": "Analysis failed"}
            
            time.sleep(10)  # Wait 10 seconds before checking again
        
        return {"status": "timeout", "reason": "Analysis timed out"}
    
    def _parse_cuckoo_report(self, report: Dict[str, Any]) -> Dict[str, Any]:
        """Parse Cuckoo Sandbox report."""
        info = report.get("info", {})
        behavior = report.get("behavior", {})
        network = report.get("network", {})
        
        # Determine verdict based on behavior
        verdict = "safe"
        confidence = "low"
        
        if behavior.get("processes"):
            # Check for suspicious processes
            suspicious_processes = []
            for process in behavior["processes"]:
                if any(suspicious in process.get("name", "").lower() for suspicious in 
                      ["cmd", "powershell", "wscript", "cscript"]):
                    suspicious_processes.append(process)
            
            if suspicious_processes:
                verdict = "suspicious"
                confidence = "medium"
        
        if network.get("tcp") or network.get("udp"):
            # Network activity detected
            if verdict == "safe":
                verdict = "suspicious"
                confidence = "low"
        
        return {
            "status": "success",
            "verdict": verdict,
            "confidence": confidence,
            "sandbox": "cuckoo",
            "analysis_time": info.get("duration", 0),
            "processes": behavior.get("processes", []),
            "network_connections": network.get("tcp", []) + network.get("udp", []),
            "files_created": behavior.get("summary", {}).get("files", []),
            "registry_modified": behavior.get("summary", {}).get("keys", [])
        }
    
    def _run_hybrid_analysis(self, file_path: str, sandbox: SandboxConfig) -> Dict[str, Any]:
        """Run analysis using Hybrid Analysis."""
        import requests
        
        # Submit file for analysis
        with open(file_path, 'rb') as f:
            files = {'file': f}
            data = {
                'environment_id': 100,  # Windows 10
                'no_share_3rd_party': True,
                'no_hash_lookup': False
            }
            headers = {
                'api-key': sandbox.api_key,
                'user-agent': 'SentinelIQ SDK'
            }
            
            response = requests.post(
                f"{sandbox.api_url}/submit/file",
                files=files,
                data=data,
                headers=headers,
                timeout=30
            )
        
        if response.status_code != 201:
            return {"status": "error", "reason": f"Submission failed: {response.status_code}"}
        
        sha256 = response.json()["sha256"]
        
        # Wait for analysis to complete
        start_time = time.time()
        while time.time() - start_time < sandbox.timeout:
            status_response = requests.get(
                f"{sandbox.api_url}/report/{sha256}/summary",
                headers=headers,
                timeout=30
            )
            
            if status_response.status_code == 200:
                status_data = status_response.json()
                if status_data.get("state") == "SUCCESS":
                    # Get full report
                    report_response = requests.get(
                        f"{sandbox.api_url}/report/{sha256}",
                        headers=headers,
                        timeout=30
                    )
                    
                    if report_response.status_code == 200:
                        return self._parse_hybrid_analysis_report(report_response.json())
                    else:
                        return {"status": "error", "reason": "Failed to get report"}
                elif status_data.get("state") == "ERROR":
                    return {"status": "error", "reason": "Analysis failed"}
            
            time.sleep(15)  # Wait 15 seconds before checking again
        
        return {"status": "timeout", "reason": "Analysis timed out"}
    
    def _parse_hybrid_analysis_report(self, report: Dict[str, Any]) -> Dict[str, Any]:
        """Parse Hybrid Analysis report."""
        verdict = report.get("verdict", "no_verdict")
        threat_score = report.get("threat_score", 0)
        
        # Convert verdict to our format
        if verdict in ["malicious", "suspicious"]:
            final_verdict = verdict
            confidence = "high" if threat_score > 50 else "medium"
        else:
            final_verdict = "safe"
            confidence = "low"
        
        return {
            "status": "success",
            "verdict": final_verdict,
            "confidence": confidence,
            "sandbox": "hybrid_analysis",
            "threat_score": threat_score,
            "threat_level": report.get("threat_level", "unknown"),
            "malware_family": report.get("malware_family", []),
            "processes": report.get("processes", []),
            "network_connections": report.get("network", {}).get("connections", []),
            "files_created": report.get("files", [])
        }
    
    def _run_anyrun_analysis(self, file_path: str, sandbox: SandboxConfig) -> Dict[str, Any]:
        """Run analysis using Any.run."""
        # Implementation for Any.run integration
        return {"status": "not_implemented", "reason": "Any.run integration not implemented"}
    
    def _perform_ml_analysis(self, file_path: str, file_info: Dict[str, Any]) -> Dict[str, Any]:
        """Perform machine learning analysis."""
        if not self.ml_model:
            return {"status": "disabled", "reason": "No ML model loaded"}
        
        try:
            # Extract features for ML model
            features = self._extract_ml_features(file_path, file_info)
            
            # Make prediction
            prediction = self.ml_model.predict([features])[0]
            prediction_proba = self.ml_model.predict_proba([features])[0]
            
            # Convert prediction to verdict
            if prediction == 1:  # Malicious
                verdict = "malicious"
                confidence = "high" if max(prediction_proba) > 0.8 else "medium"
            else:  # Benign
                verdict = "safe"
                confidence = "high" if max(prediction_proba) > 0.8 else "medium"
            
            return {
                "status": "success",
                "verdict": verdict,
                "confidence": confidence,
                "prediction": int(prediction),
                "probabilities": prediction_proba.tolist(),
                "features_used": len(features)
            }
            
        except Exception as e:
            return {"status": "error", "reason": str(e)}
    
    def _extract_ml_features(self, file_path: str, file_info: Dict[str, Any]) -> List[float]:
        """Extract features for machine learning model."""
        features = []
        
        # File size features
        features.append(file_info["size"])
        features.append(1 if file_info["size"] > 1024 * 1024 else 0)  # > 1MB
        
        # File type features
        features.append(1 if file_info["extension"] in [".exe", ".dll", ".sys"] else 0)
        features.append(1 if file_info["extension"] in [".bat", ".cmd", ".scr"] else 0)
        
        # Entropy features
        entropy_analysis = self._analyze_entropy(file_path)
        features.append(entropy_analysis.get("overall_entropy", 0))
        features.append(1 if entropy_analysis.get("is_packed", False) else 0)
        features.append(1 if entropy_analysis.get("is_encrypted", False) else 0)
        
        # String analysis features
        string_analysis = self._analyze_strings(file_path)
        features.append(string_analysis.get("suspicious_count", 0))
        features.append(1 if string_analysis.get("suspicious_count", 0) > 10 else 0)
        
        # PE features (if applicable)
        if file_info["extension"] in [".exe", ".dll", ".sys"]:
            pe_analysis = self._analyze_pe_file(file_path)
            features.append(len(pe_analysis.get("suspicious_characteristics", [])))
            features.append(len(pe_analysis.get("imports", [])))
        else:
            features.extend([0, 0])  # Padding for non-PE files
        
        return features
    
    def _combine_analysis_results(self, file_path: str, file_info: Dict[str, Any], 
                                 static_analysis: Dict[str, Any], dynamic_analysis: Dict[str, Any], 
                                 ml_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Combine all analysis results into final report."""
        # Calculate weighted scores
        scores = []
        weights = []
        
        # Static analysis score
        static_verdict = static_analysis.get("verdict", "unknown")
        static_confidence = static_analysis.get("confidence", "low")
        static_score = self._verdict_to_score(static_verdict)
        static_weight = self._confidence_to_weight(static_confidence)
        scores.append(static_score)
        weights.append(static_weight)
        
        # Dynamic analysis score
        if dynamic_analysis.get("status") == "success":
            dynamic_verdict = dynamic_analysis.get("verdict", "unknown")
            dynamic_confidence = dynamic_analysis.get("confidence", "low")
            dynamic_score = self._verdict_to_score(dynamic_verdict)
            dynamic_weight = self._confidence_to_weight(dynamic_confidence)
            scores.append(dynamic_score)
            weights.append(dynamic_weight)
        
        # ML analysis score
        if ml_analysis.get("status") == "success":
            ml_verdict = ml_analysis.get("verdict", "unknown")
            ml_confidence = ml_analysis.get("confidence", "low")
            ml_score = self._verdict_to_score(ml_verdict)
            ml_weight = self._confidence_to_weight(ml_confidence)
            scores.append(ml_score)
            weights.append(ml_weight)
        
        # Calculate final verdict
        if scores and weights:
            weighted_score = sum(s * w for s, w in zip(scores, weights)) / sum(weights)
            final_verdict = self._score_to_verdict(weighted_score)
            final_confidence = self._calculate_final_confidence(weights)
        else:
            final_verdict = "unknown"
            final_confidence = "low"
        
        # Build comprehensive report
        report = {
            "observable": file_path,
            "data_type": "file",
            "verdict": final_verdict,
            "confidence": final_confidence,
            "analysis_timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            "file_info": file_info,
            "static_analysis": static_analysis,
            "dynamic_analysis": dynamic_analysis,
            "ml_analysis": ml_analysis,
            "taxonomy": self._build_taxonomy(final_verdict, final_confidence, static_analysis, dynamic_analysis),
            "artifacts": self._extract_artifacts(file_info, static_analysis, dynamic_analysis),
            "operations": self._build_operations(final_verdict, file_path, file_info)
        }
        
        return report
    
    def _verdict_to_score(self, verdict: str) -> float:
        """Convert verdict to numeric score."""
        verdict_scores = {
            "malicious": 1.0,
            "suspicious": 0.5,
            "safe": 0.0,
            "unknown": 0.25
        }
        return verdict_scores.get(verdict, 0.25)
    
    def _confidence_to_weight(self, confidence: str) -> float:
        """Convert confidence to weight."""
        confidence_weights = {
            "high": 1.0,
            "medium": 0.7,
            "low": 0.4
        }
        return confidence_weights.get(confidence, 0.4)
    
    def _score_to_verdict(self, score: float) -> str:
        """Convert numeric score to verdict."""
        if score >= 0.7:
            return "malicious"
        elif score >= 0.4:
            return "suspicious"
        elif score >= 0.1:
            return "safe"
        else:
            return "unknown"
    
    def _calculate_final_confidence(self, weights: List[float]) -> str:
        """Calculate final confidence based on weights."""
        if not weights:
            return "low"
        
        avg_weight = sum(weights) / len(weights)
        if avg_weight >= 0.8:
            return "high"
        elif avg_weight >= 0.6:
            return "medium"
        else:
            return "low"
    
    def _build_taxonomy(self, verdict: str, confidence: str, static_analysis: Dict[str, Any], 
                       dynamic_analysis: Dict[str, Any]) -> List[Dict[str, str]]:
        """Build taxonomy entries from analysis results."""
        taxonomy = []
        
        # Main verdict taxonomy
        taxonomy.append(
            self.build_taxonomy(
                level=verdict,
                namespace="malware_analysis",
                predicate="overall",
                value=confidence
            )
        )
        
        # Static analysis taxonomy
        if static_analysis.get("yara_matches"):
            taxonomy.append(
                self.build_taxonomy(
                    level="info",
                    namespace="malware_analysis",
                    predicate="yara_matches",
                    value=str(len(static_analysis["yara_matches"]))
                )
            )
        
        # Dynamic analysis taxonomy
        if dynamic_analysis.get("status") == "success":
            taxonomy.append(
                self.build_taxonomy(
                    level=dynamic_analysis.get("verdict", "unknown"),
                    namespace="malware_analysis",
                    predicate="sandbox",
                    value=dynamic_analysis.get("sandbox", "unknown")
                )
            )
        
        return taxonomy
    
    def _extract_artifacts(self, file_info: Dict[str, Any], static_analysis: Dict[str, Any], 
                          dynamic_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Extract artifacts from analysis results."""
        artifacts = []
        
        # File hash artifacts
        for hash_type, hash_value in file_info.get("hashes", {}).items():
            artifacts.append(
                self.build_artifact("hash", hash_value, tlp=2, extra={
                    "hash_type": hash_type,
                    "filename": file_info.get("filename", "unknown")
                })
            )
        
        # Network artifacts from dynamic analysis
        if dynamic_analysis.get("status") == "success":
            for connection in dynamic_analysis.get("network_connections", []):
                if "ip" in connection:
                    artifacts.append(
                        self.build_artifact("ip", connection["ip"], tlp=2, extra={
                            "port": connection.get("port"),
                            "protocol": connection.get("protocol"),
                            "source": "sandbox"
                        })
                    )
        
        return artifacts
    
    def _build_operations(self, verdict: str, file_path: str, file_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Build follow-up operations based on analysis results."""
        operations = []
        
        if verdict == "malicious":
            # Quarantine the file
            operations.append(
                self.build_operation(
                    "quarantine",
                    target=file_path,
                    priority="high",
                    description="Quarantine malicious file"
                )
            )
            
            # Block file hash
            for hash_type, hash_value in file_info.get("hashes", {}).items():
                operations.append(
                    self.build_operation(
                        "block_hash",
                        hash_type=hash_type,
                        hash_value=hash_value,
                        priority="high",
                        description=f"Block {hash_type} hash"
                    )
                )
            
            # Send alert
            operations.append(
                self.build_operation(
                    "alert",
                    severity="high",
                    target=file_path,
                    description="Malicious file detected"
                )
            )
        
        elif verdict == "suspicious":
            # Monitor the file
            operations.append(
                self.build_operation(
                    "monitor",
                    target=file_path,
                    duration="24h",
                    description="Monitor suspicious file"
                )
            )
            
            # Investigate further
            operations.append(
                self.build_operation(
                    "investigate",
                    target=file_path,
                    priority="medium",
                    description="Investigate suspicious file"
                )
            )
        
        return operations
    
    def _cleanup_temp_files(self) -> None:
        """Clean up temporary files."""
        try:
            import shutil
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception as e:
            print(f"Warning: Failed to clean up temp files: {e}")


if __name__ == "__main__":
    # Example usage
    input_data = {
        "dataType": "file",
        "filename": "suspicious.exe",
        "tlp": 2,
        "pap": 2,
        "config": {
            "custom_yara_rules": [
                {
                    "name": "custom_malware",
                    "path": "/path/to/custom_rules.yar",
                    "weight": 1.5
                }
            ],
            "cuckoo_api_key": "your_cuckoo_api_key",
            "cuckoo_api_url": "http://localhost:8090",
            "hybrid_analysis_api_key": "your_ha_api_key",
            "ml_model_path": "/path/to/ml_model.pkl",
            "auto_extract": True
        }
    }
    
    analyzer = MalwareAnalysisAnalyzer(input_data)
    analyzer.run()
```

## Configuration

### YARA Rules

Create YARA rules for malware detection:

```yara
// rules/malware_generic.yar
rule Malware_Generic {
    meta:
        description = "Generic malware detection rule"
        author = "SentinelIQ Team"
        version = "1.0"
    
    strings:
        $s1 = "CreateProcess" ascii
        $s2 = "WriteProcessMemory" ascii
        $s3 = "VirtualAlloc" ascii
        $s4 = "LoadLibrary" ascii
        $s5 = "GetProcAddress" ascii
    
    condition:
        3 of them
}

// rules/ransomware.yar
rule Ransomware {
    meta:
        description = "Ransomware detection rule"
        author = "SentinelIQ Team"
        version = "1.0"
    
    strings:
        $s1 = "encrypt" ascii
        $s2 = "decrypt" ascii
        $s3 = "ransom" ascii
        $s4 = "bitcoin" ascii
        $s5 = "wallet" ascii
    
    condition:
        3 of them
}
```

### Sandbox Configuration

```json
{
  "dataType": "file",
  "filename": "suspicious.exe",
  "tlp": 2,
  "pap": 2,
  "config": {
    "cuckoo_api_key": "your_cuckoo_api_key",
    "cuckoo_api_url": "http://localhost:8090",
    "hybrid_analysis_api_key": "your_ha_api_key",
    "anyrun_api_key": "your_anyrun_api_key",
    "ml_model_path": "/path/to/ml_model.pkl",
    "auto_extract": true
  }
}
```

## Output Example

```json
{
  "success": true,
  "summary": {
    "verdict": "malicious",
    "confidence": "high",
    "analysis_methods": ["static", "dynamic", "ml"]
  },
  "artifacts": [
    {
      "dataType": "hash",
      "data": "a1b2c3d4e5f6...",
      "tlp": 2,
      "extra": {
        "hash_type": "sha256",
        "filename": "suspicious.exe"
      }
    }
  ],
  "operations": [
    {
      "operation_type": "quarantine",
      "parameters": {
        "target": "/path/to/suspicious.exe",
        "priority": "high",
        "description": "Quarantine malicious file"
      }
    }
  ],
  "full": {
    "observable": "/path/to/suspicious.exe",
    "data_type": "file",
    "verdict": "malicious",
    "confidence": "high",
    "analysis_timestamp": "2024-01-01T12:00:00Z",
    "file_info": {
      "filename": "suspicious.exe",
      "size": 1024000,
      "hashes": {
        "md5": "a1b2c3d4e5f6...",
        "sha1": "b2c3d4e5f6a1...",
        "sha256": "c3d4e5f6a1b2..."
      }
    },
    "static_analysis": {
      "yara_matches": [
        {
          "rule_name": "Malware_Generic",
          "weight": 1.0,
          "strings": ["CreateProcess", "WriteProcessMemory"]
        }
      ],
      "pe_analysis": {
        "suspicious_characteristics": ["Executable section", "Suspicious imports"]
      }
    },
    "dynamic_analysis": {
      "status": "success",
      "verdict": "malicious",
      "sandbox": "cuckoo",
      "processes": ["suspicious.exe", "cmd.exe"]
    },
    "ml_analysis": {
      "status": "success",
      "verdict": "malicious",
      "prediction": 1,
      "probabilities": [0.1, 0.9]
    }
  }
}
```

## Features Demonstrated

1. **Static Analysis**: YARA rules, PE analysis, entropy analysis
2. **Dynamic Analysis**: Sandbox integration with multiple providers
3. **Machine Learning**: ML model integration for classification
4. **Comprehensive Reporting**: Detailed analysis results
5. **Artifact Extraction**: Hash and network artifact extraction
6. **Operation Generation**: Automated response operations
7. **Error Handling**: Robust error handling and recovery
8. **Configuration**: Flexible configuration for different environments

## Dependencies

Install required dependencies:

```bash
pip install yara-python pefile joblib requests aiohttp
```

## Best Practices

1. **Rule Management**: Keep YARA rules updated and organized
2. **Sandbox Security**: Use isolated sandbox environments
3. **ML Model Training**: Regularly retrain ML models with new data
4. **Performance**: Optimize for large file processing
5. **Security**: Handle sensitive files securely
6. **Monitoring**: Monitor analysis performance and costs
7. **Logging**: Implement comprehensive logging
8. **Testing**: Test with known malware samples

## Next Steps

- [Network Monitoring Example](network-monitoring.md) - Network security monitoring
- [Incident Response Example](incident-response.md) - Automated response workflows
- [Advanced Features](../tutorials/advanced-features.md) - Advanced techniques
