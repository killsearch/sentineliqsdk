---
description: Producer and Consumer development patterns and requirements
---

# Producer/Consumer Development Patterns

This rule defines the patterns and requirements for implementing Producer and Consumer modules in the SentinelIQ SDK.

## File Organization

### Producers
- **Code**: `src/sentineliqsdk/producers/<name>.py`
- **Example**: `examples/producers/<name>_example.py`
- **Tests**: `tests/producers/test_<name>.py`
- **Class naming**: `<Name>Producer` extending `sentineliqsdk.producers.Producer`

### Consumers
- **Code**: `src/sentineliqsdk/consumers/<name>.py`
- **Example**: `examples/consumers/<name>_example.py`
- **Tests**: `tests/consumers/test_<name>.py`
- **Class naming**: `<Name>Consumer` extending `sentineliqsdk.consumers.Consumer`

## Required Imports and Structure

### Producer Base Pattern
```python
from __future__ import annotations

from sentineliqsdk.messaging import Message, ProducerReport
from sentineliqsdk.models import ModuleMetadata, WorkerInput
from sentineliqsdk.producers.base import Producer

class MyProducer(Producer):
    METADATA = ModuleMetadata(
        name="My Producer",
        description="Description of what this producer does",
        author=("SentinelIQ Team <team@sentineliq.com.br>",),
        pattern="kafka",  # or "rabbitmq", "redis", etc.
        doc_pattern="Producer documentation pattern",
        doc="https://killsearch.github.io/sentineliqsdk/modulos/producers/my_producer/",
        version_stage="TESTING",
    )

    def publish(self, message: Message) -> ProducerReport:
        """Publish a message to the configured queue."""
        # Implementation here
        pass

    def run(self) -> ProducerReport:
        """Override to implement publishing logic."""
        # Implementation here
        pass
```

### Consumer Base Pattern
```python
from __future__ import annotations

from sentineliqsdk.consumers.base import Consumer
from sentineliqsdk.messaging import ConsumerReport, Message
from sentineliqsdk.models import ModuleMetadata, WorkerInput

class MyConsumer(Consumer):
    METADATA = ModuleMetadata(
        name="My Consumer",
        description="Description of what this consumer does",
        author=("SentinelIQ Team <team@sentineliq.com.br>",),
        pattern="kafka",  # or "rabbitmq", "redis", etc.
        doc_pattern="Consumer documentation pattern",
        doc="https://killsearch.github.io/sentineliqsdk/modulos/consumers/my_consumer/",
        version_stage="TESTING",
    )

    def consume(self, message: Message) -> ConsumerReport:
        """Process a consumed message."""
        # Implementation here
        pass

    def start_consuming(self) -> ConsumerReport:
        """Start consuming messages from the configured queue."""
        # Implementation here
        pass
```

## Configuration Requirements

### Secrets Configuration
Always use `WorkerConfig.secrets` for credentials, never `os.environ`:

```python
# CORRECT
input_data = WorkerInput(
    data_type="other",
    data="data",
    config=WorkerConfig(
        secrets={
            "kafka.bootstrap_servers": "localhost:9092",
            "kafka.security_protocol": "PLAINTEXT",
            "kafka.sasl_username": "user",
            "kafka.sasl_password": "password",
        }
    ),
)

# PROHIBITED
import os
os.environ["KAFKA_BOOTSTRAP_SERVERS"] = "localhost:9092"
```

### Queue Configuration
Always configure queue settings:

```python
from sentineliqsdk.messaging import QueueConfig, MessageConfig

# Configure queue
queue_config = QueueConfig(
    queue_name="my-topic",
    durable=True,
    auto_delete=False,
)
producer.configure_queue(queue_config)

# Configure messaging
message_config = MessageConfig(
    delivery_mode="persistent",
    mandatory=True,
)
producer.configure_messaging(message_config)
```

## Example Requirements

### Producer Example Structure
```python
from __future__ import annotations

import argparse
import json
import sys

from sentineliqsdk import WorkerConfig, WorkerInput
from sentineliqsdk.messaging import MessageConfig, QueueConfig
from sentineliqsdk.producers import MyProducer

def main() -> None:
    parser = argparse.ArgumentParser(description="My Producer Example")
    parser.add_argument("--data", default="Hello World!", help="Data to publish")
    parser.add_argument("--topic", default="my-topic", help="Topic name")
    parser.add_argument("--execute", action="store_true", help="Execute real publishing")
    parser.add_argument("--include-dangerous", action="store_true", help="Include dangerous operations")
    
    args = parser.parse_args()
    
    # Create input data with secrets
    input_data = WorkerInput(
        data_type="other",
        data=args.data,
        config=WorkerConfig(
            secrets={
                "kafka.bootstrap_servers": "localhost:9092",
                "kafka.security_protocol": "PLAINTEXT",
            }
        ),
    )
    
    # Create and configure producer
    producer = MyProducer(input_data)
    producer.configure_queue(QueueConfig(queue_name=args.topic))
    producer.configure_messaging(MessageConfig(delivery_mode="persistent"))
    
    if args.execute:
        try:
            report = producer.run()
            result = {
                "success": report.success,
                "message_id": report.message_id,
                "queue_name": report.queue_name,
                "delivery_confirmed": report.delivery_confirmed,
            }
            print(json.dumps(result, ensure_ascii=False, indent=2))
        except Exception as e:
            error_result = {"success": False, "error": str(e)}
            print(json.dumps(error_result, ensure_ascii=False, indent=2))
            sys.exit(1)
        finally:
            producer.close()
    else:
        # Dry run
        dry_run_result = {
            "mode": "dry_run",
            "message": "Would publish the following message:",
            "data": args.data,
            "topic": args.topic,
            "note": "Use --execute to actually publish the message",
        }
        print(json.dumps(dry_run_result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
```

### Consumer Example Structure
```python
from __future__ import annotations

import argparse
import json
import sys

from sentineliqsdk import WorkerConfig, WorkerInput
from sentineliqsdk.consumers import MyConsumer
from sentineliqsdk.messaging import MessageConfig, QueueConfig

def main() -> None:
    parser = argparse.ArgumentParser(description="My Consumer Example")
    parser.add_argument("--topic", default="my-topic", help="Topic to consume")
    parser.add_argument("--group-id", default="my-consumer", help="Consumer group ID")
    parser.add_argument("--max-messages", type=int, default=5, help="Maximum messages to consume")
    parser.add_argument("--execute", action="store_true", help="Execute real consumption")
    parser.add_argument("--include-dangerous", action="store_true", help="Include dangerous operations")
    
    args = parser.parse_args()
    
    # Create input data with secrets
    input_data = WorkerInput(
        data_type="other",
        data="consumer_data",
        config=WorkerConfig(
            params={
                "max_messages": args.max_messages,
                "timeout_ms": 5000,
            },
            secrets={
                "kafka.bootstrap_servers": "localhost:9092",
                "kafka.security_protocol": "PLAINTEXT",
                "kafka.group_id": args.group_id,
            }
        ),
    )
    
    # Create and configure consumer
    consumer = MyConsumer(input_data)
    consumer.configure_queue(QueueConfig(queue_name=args.topic))
    consumer.configure_messaging(MessageConfig(auto_ack=False))
    
    if args.execute:
        try:
            report = consumer.start_consuming()
            result = {
                "success": report.success,
                "messages_processed": report.messages_processed,
                "messages_failed": report.messages_failed,
                "processing_time": report.processing_time,
            }
            print(json.dumps(result, ensure_ascii=False, indent=2))
        except Exception as e:
            error_result = {"success": False, "error": str(e)}
            print(json.dumps(error_result, ensure_ascii=False, indent=2))
            sys.exit(1)
        finally:
            consumer.stop()
    else:
        # Dry run
        dry_run_result = {
            "mode": "dry_run",
            "message": "Would consume messages from the following topic:",
            "topic": args.topic,
            "group_id": args.group_id,
            "max_messages": args.max_messages,
            "note": "Use --execute to actually consume messages",
        }
        print(json.dumps(dry_run_result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
```

## Safety Gates

All examples must implement safety gates:
- `--execute`: Enable real network calls (default: dry-run)
- `--include-dangerous`: Enable impactful operations (scans, blocks, etc.)
- Default behavior should be safe and non-destructive

## Error Handling

### Producer Error Handling
```python
def publish(self, message: Message) -> ProducerReport:
    try:
        # Publishing logic here
        full_report = {
            "message_id": message.metadata.message_id,
            "delivery_confirmed": True,
            "metadata": self.METADATA.to_dict(),
        }
        return self.report(full_report)
    except Exception as e:
        full_report = {
            "message_id": message.metadata.message_id,
            "delivery_confirmed": False,
            "error_message": str(e),
            "metadata": self.METADATA.to_dict(),
        }
        return self.report(full_report)
```

### Consumer Error Handling
```python
def consume(self, message: Message) -> ConsumerReport:
    try:
        # Processing logic here
        self._record_success()
        full_report = {
            "message_id": message.metadata.message_id,
            "processing_result": result,
            "metadata": self.METADATA.to_dict(),
        }
        return self.report(full_report)
    except Exception as e:
        self._record_failure()
        full_report = {
            "message_id": message.metadata.message_id,
            "error_message": str(e),
            "metadata": self.METADATA.to_dict(),
        }
        return self.report(full_report)
```

## Documentation Requirements

### Required Documentation Files
- `docs/modulos/producers/<name>.md` - Producer documentation
- `docs/modulos/consumers/<name>.md` - Consumer documentation

### Documentation Structure
Each documentation file must include:
- **Characteristics**: Key features and capabilities
- **Basic Usage**: Simple example with `WorkerInput` and `WorkerConfig.secrets`
- **Configuration**: All available secrets and parameters
- **Complete Example**: Full working example
- **Error Handling**: How errors are handled
- **Dependencies**: Required packages

### Navigation Updates
Update `mkdocs.yml` navigation under the "Modules" section:
```yaml
nav:
  - Modules:
    - Producers:
      - Kafka Producer: modulos/producers/kafka_producer.md
    - Consumers:
      - Kafka Consumer: modulos/consumers/kafka_consumer.md
```

## Checklist for New Producer/Consumer

### Code Requirements
- [ ] Naming and imports compliant
- [ ] `METADATA` attribute declared and included in full_report
- [ ] `publish()`/`consume()` and `start_consuming()` implemented
- [ ] Calls `self.report(...)` with appropriate report type
- [ ] Error handling implemented

### Testing
- [ ] Tests added under `tests/producers/test_<name>.py` or `tests/consumers/test_<name>.py`
- [ ] `poe lint` passes
- [ ] `poe test` passes

### Examples
- [ ] Example under `examples/producers/` or `examples/consumers/` runnable
- [ ] Prints compact result to STDOUT
- [ ] Supports `--execute` for real calls
- [ ] Supports `--include-dangerous` for impactful operations
- [ ] Uses `WorkerConfig.secrets` for credentials (never `os.environ`)

### Documentation
- [ ] Docs updated (Guides/Tutorials/Examples/Reference)
- [ ] Links added to relevant pages
- [ ] `mkdocs.yml` updated if needed
- [ ] `poe docs` passes locally
- [ ] Programmatic docs page added: `docs/modulos/producers/<name>.md` or `docs/modulos/consumers/<name>.md`